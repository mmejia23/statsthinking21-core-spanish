---
output:
  html_document: default
  pdf_document: default
  bookdown::gitbook:
    lib_dir: "book_assets"
    includes:
      in_header: google_analytics.html
---
<!-- # Comparing means -->
# Comparar medias

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(tidyverse)
library(ggplot2)
library(tidyr)
library(fivethirtyeight)
#library(BayesMed)
library(BayesFactor)
library(lme4)
library(lmerTest)
library(cowplot)
library(knitr)
library(emmeans)

set.seed(123456) # set random seed to exactly replicate results

# load the NHANES data library
library(NHANES)

# drop duplicated IDs within the NHANES dataset
NHANES <- 
  NHANES %>% 
  dplyr::distinct(ID,.keep_all=TRUE)

NHANES_adult <- 
  NHANES %>%
  subset(Age>=18) %>%
  drop_na(BMI)


```

<!-- We have already encountered a number of cases where we wanted to ask questions about the mean of a sample.  In this chapter, we will delve deeper into the various ways that we can compare means across groups. -->
Hemos encontrado ya un número de casos donde queremos hacer preguntas acerca de la media de una muestra. En este capítulo, profundizaremos en las varias maneras en que podemos comparar medias entre grupos.


<!-- ## Testing the value of a single mean {#single-mean} -->
## Probar el valor de una media simple {#single-mean}

<!-- The simplest question we might want to ask of a mean is whether it has a specific value.  Let's say that we want to test whether the mean diastolic blood pressure value in adults from the NHANES dataset is above 80, which is cutoff for hypertension according to the American College of Cardiology.  We take a sample of 200 adults in order to ask this question; each adult had their blood pressure measured three times, and we use the average of these for our test. -->
La pregunta más sencilla que podríamos hacernos acerca de una media es si tiene un valor específico. Digamos que queremos probar si el valor medio de presión sanguínea diastólica en adultos de la base de datos NHANES es mayor a 80, que es un punto de corte para hipertensión de acuerdo al Colegio Americano de Cardiología. Tomamos una muestra de 200 adultos para hacernos esta pregunta; cada adulto tiene su presión sanguínea medida en tres momentos, y usaremos el promedio de estos valores para nuestra prueba.

```{r echo=FALSE}
NHANES_sample <-
  NHANES_adult %>%
  drop_na(BPDiaAve) %>%
  mutate(Hypertensive = BPDiaAve > 80) %>%
  sample_n(200)

```


<!-- One simple way to test for this difference is using a test called the *sign test*, which asks whether the proportion of positive differences between the actual value and the hypothesized value is different than what we would expect by chance.  To do this, we take the differences between each data point and the hypothesized mean value and compute their sign.  If the data are normally distributed and the actual mean is equal to the hypothesized mean, then the proportion of values above the hypothesized mean (or below it) should be 0.5, such that the proportion of positive differences should also be 0.5.  In our sample, we see that `r I(sprintf('%0.1f',mean(NHANES_sample$Hypertensive)*100))` percent of individuals have a diastolic blood pressure above 80.  We can then use a binomial test to ask whether this proportion of positive differences is greater than 0.5, using the binomial testing function in our statistical software: -->
Una manera sencilla de probar esta diferencia es usando una prueba llamada la *prueba de los signos*, que se pregunta si la proporción de diferencias positivas entre el valor real y el valor hipotetizado es diferente que el que se esperaría por azar. Para hacer esto, tomamos las diferencias entre cada dato y el valor de la media hipotetizada y calculamos su signo. Si los datos están normalmente distribuidos y la media real es igual a la media hipotetizada, entonces la proporción de valores arriba de la media hipotetizada (o por debajo) debería ser 0.5, de tal manera que la proporción de diferencias positivas también debería ser de 0.5. En nuestra muestra, vemos que el `r I(sprintf('%0.1f',mean(NHANES_sample$Hypertensive)*100))` por ciento de las personas tienen una presión sanguínea diastólica arriba de 80. Luego podemos usar una prueba binomial para preguntarnos si la proporción de diferencias positivas es mayor a 0.5, usando la función de prueba binomial en nuestro software estadístico:

```{r echo=FALSE}
# compute sign test for differences between first and second measurement
npos <- sum(NHANES_sample$Hypertensive)
bt <- binom.test(npos, nrow(NHANES_sample), alternative='greater')
bt
```

<!-- Here we see that the proportion of individuals with positive signs is not very surprising under the null hypothesis of $p=0.5$.  -->
Aquí vemos que la proporción de personas con signo positivo no es muy sorprendente bajo la hipótesis nula de $p=0.5$.

<!-- We can also ask this question using Student's t-test, which you have already encountered earlier in the book.  We will refer to the mean as $\bar{X}$ and the hypothesized population mean as $\mu$.  Then, the t test for a single mean is: -->
También podemos hacer esta pregunta usando la prueba t de Student, que ya te has encontrado antes en este libro. Nos referiremos a la media como $\bar{X}$ y a la media poblacional hipotetizada como $\mu$. Entonces, la prueba t para una sola media es:

$$
t = \frac{\bar{X} - \mu}{SEM}
$$
<!-- where SEM (as you may remember from the chapter on sampling) is defined as: -->
donde SEM (*standard error of the mean*, o *error estándar de la media*, como podrás recordar del capítulo sobre muestreo) es definida por:

$$
SEM = \frac{\hat{\sigma}}{\sqrt{n}}
$$

<!-- In essence, the t statistic asks how large the deviation of the sample mean from the hypothesized quantity is with respect to the sampling variability of the mean. -->
En esencia, el estadístico t pregunta qué tan grande es la desviación de la media muestral de la cantidad hipotetizada con respecto a la variabilidad muestral de la media.

<!-- We can compute this for the NHANES dataset using our statistical software: -->
Podemos calcular esto para la base de datos NHANES en nuestro software estadístico:

```{r echo=FALSE, warning=FALSE, message=FALSE}

tt = t.test(x=NHANES_adult$BPDiaAve, mu=80, alternative='greater')
tt
```

<!-- This shows us that the mean diastolic blood pressure in the dataset (`r I(sprintf('%0.1f', tt$estimate))`) is actually much lower than 80, so our test for whether it is above 80 is very far from significance. -->
Esto nos muestra que la media de presión sanguínea diastólica en la base de datos (`r I(sprintf('%0.1f', tt$estimate))`) es realmente mucho menor que 80, por lo que nuestra prueba sobre si la media es superior a 80 está muy lejos de significatividad.

<!-- Remember that a large p-value doesn't provide us with evidence in favor of the null hypothesis, since we had already assumed that the null hypothesis is true to start with. However, as we discussed in the chapter on Bayesian analysis, we can use the Bayes factor to quantify evidence for or against the null hypothesis: -->
Recuerda que un valor p grande no nos provee de evidencia en favor de la hipótesis nula, porque hemos asumido desde el inicio que la hipótesis nula es verdadera. Sin embargo, como discutimos en el capítulo sobre análisis Bayesiano, podemos usar el factor de Bayes para cuantificar la evidencia a favor o en contra de la hipótesis nula:

```{r message=FALSE, warning=FALSE}
ttestBF(NHANES_sample$BPDiaAve, mu=80, nullInterval=c(-Inf, 80))
```

<!-- The first Bayes factor listed here ($2.73 * 10^{16}$) denotes the fact that there is exceedingly strong evidence in favor of the null hypothesis over the alternative. -->
El primer factor de Bayes enlistado aquí ($2.73 * 10^{16}$) denota el hecho de que hay una evidencia excesivamente fuerte en favor de la hipóteis nula sobre la alternativa.

<!-- ## Comparing two means {#comparing-two-means} -->
## Comparar dos medias {#comparing-two-means}

<!-- A more common question that often arises in statistics is whether there is a difference between the means of two different groups.  Let's say that we would like to know whether regular marijuana smokers watch more television, which we can also ask using the NHANES dataset. We take a sample of 200 individuals from the dataset and test whether the number of hours of television watching per day is related to regular marijuana use.  The left panel of Figure \@ref(fig:PotTVViolin) shows these data using a violin plot. -->
Una pregunta común que frecuentemente surge en estadística es si existe una diferencia entre las medias de dos grupos diferentes. Digamos que quisiéramos saber si fumadores regulares de marihuana miran más televisión, que también podemos preguntarnos usando la base de datos NHANES. Tomamos una muestra de 200 personas de la base de datos y probamos si el número de horas de ver televisión por día está relacionado con el uso regular de marihuana. El panel izquierdo de la Figura \@ref(fig:PotTVViolin) muestra estos datos usando una gráfica de violín.

<!-- Left: Violin plot showing distributions of TV watching separated by regular marijuana use. Right: Violin plots showing data for each group, with a dotted line connecting the predicted values for each group, computed on the basis of the results of the linear model.. -->
```{r PotTVViolin,echo=FALSE,fig.cap='Izquierda: Gráfica de violín mostrando distribuciones de horas de ver TV por día separados por el uso regular de marihuana. Derecha: Gráficas de violín mostrando los datos para cada grupo, con una línea punteada conectando los valores predichos para cada grupo, calculado en base a los resultados del modelo lineal.',fig.width=8,fig.height=4,out.height='50%'}

# create sample with tv watching and marijuana use
NHANES_sample <-
  NHANES_adult %>%
  drop_na(TVHrsDay, RegularMarij) %>%
  mutate(
    TVHrsNum = recode( #recode character values into numerical values
      TVHrsDay,
      "More_4_hr" = 5,
      "4_hr" = 4, 
      "2_hr" = 2,
      "1_hr" = 1, 
      "3_hr" = 3, 
      "0_to_1_hr" = 0.5,
      "0_hrs" = 0
    )
  ) %>%
  sample_n(200)

p1 <- ggplot(NHANES_sample,aes(RegularMarij,TVHrsNum)) +
  geom_violin(draw_quantiles=.50) +
  labs(
    x = "Regular marijuana user",
    y = "TV hours per day"
  )

lm_summary <- summary(lm(TVHrsNum ~ RegularMarij, data = NHANES_sample))

ttresult <- t.test(
  TVHrsNum ~ RegularMarij,
  data = NHANES_sample,
  var.equal = TRUE,
  alternative = 'less'
)

p2 <- ggplot(NHANES_sample,aes(RegularMarij,TVHrsNum)) +
  geom_violin() +
  annotate('segment',x=1,y=lm_summary$coefficients[1,1],
           xend=2,
           yend=lm_summary$coefficients[1,1]+lm_summary$coefficients[2,1],
           linetype='dotted') +
  labs(
    x = "Regular marijuana user",
    y = "TV hours per day"
  )

plot_grid(p1, p2)
```

<!-- We can also use Student's t test to test for differences between two groups of independent observations (as we saw in an earlier chapter); we will turn later in the chapter to cases where the observations are not independent.  As a reminder, the t-statistic for comparison of two independent groups is computed as: -->
También podemos usar la prueba t de Student para probar diferencias entre dos grupos de observaciones independientes (como revisamos en un capítulo anterior); regresaremos después en este capítulo a casos donde las observaciones no son independientes. Como recordatorio, el estadístico t para comparaciones entre dos grupos independientes se calcula así:

$$
t = \frac{\bar{X_1} - \bar{X_2}}{\sqrt{\frac{S_1^2}{n_1} + \frac{S_2^2}{n_2}}}
$$

<!-- where $\bar{X}_1$ and $\bar{X}_2$ are the means of the two groups, $S^2_1$ and $S^2_2$ are the variances for each of the groups, and $n_1$ and $n_2$ are the sizes of the two groups.  Under the null hypothesis of no difference between means, this statistic is distributed according to a t distribution with N - 2 degrees of freedom (since we have computed two parameter estimates, namely the means of the two groups). In this case, we started with the specific hypothesis that smoking marijuana is associated with greater TV watching, so we will use a one-tailed test.  Here are the results from our statistical software: -->
donde $\bar{X}_1$ y $\bar{X}_2$ son las medias de los dos grupos, $S^2_1$ y $S^2_2$ son las varianzas para cada grupo, y $n_1$ y $n_2$ son los tamaños de los dos grupos. Bajo la hipótesis nula de no diferencia entre medias, este estadístico se distribuye de acuerdo a una distribución t con N - 2 grados de libertad (como hemos calculado dos estimaciones de parámetros, que fueron las medias de los dos grupos). En este caso, comenzamos con la hipótesis específica de que fumar marihuana está asociado con mayor tiempo de ver TV, por lo que usaremos una prueba de una cola. Aquí están los resultados de nuestro software estadístico:

```{r echo=FALSE,warning=FALSE}
# compute t test for tv watching as function of marijuana use
ttresult
```

<!-- In this case we see that there is a statistically significant difference between groups, in the expected direction - regular pot smokers watch more TV. -->
En este caso vemos que existe una diferencia estadísticamente significativa entre los grupos, en la dirección esperada - fumadores regulares de marihuana ven más TV.

<!-- ## The t-test as a linear model {#ttest-linear-model} -->
## La prueba t como un modelo lineal {#ttest-linear-model}

<!-- The t-test is often presented as a specialized tool for comparing means, but it can also be viewed as an application of the general linear model.  In this case, the model would look like this: -->
La prueba t es frecuentemente presentada como una herramienta especializada para comparar medias, pero también se puede ver como una aplicación del modelo lineal general. En este caso, el modelo se vería como esto:

$$
\hat{TV} = \hat{\beta_1}*Marijuana + \hat{\beta_0}
$$
<!-- Since smoking is a binary variable, we treat it as a *dummy variable* like we discussed in the previous chapter, setting it to a value of 1 for smokers and zero for nonsmokers.  In that case, $\hat{\beta_1}$ is simply the difference in means between the two groups, and $\hat{\beta_0}$ is the mean for the group that was coded as zero.  We can fit this model using the general linear model function in our statistical software, and see that it gives the same t statistic as the t-test above, except that it's negative in this case because of the way that our software arranges the groups: -->
Como el fumar es una variable binaria, la tratamos como una *variable ficticia* (*dummy variable*) como discutimos en el capítulo anterior, fijándola en un valor de 1 para fumadores o de cero para no fumadores. En este caso, $\hat{\beta_1}$ es simplemente la diferencia de las medias entre los dos grupos, y $\hat{\beta_0}$ es la media para el grupo que fue codificado con cero. Podemos ajustar este modelo usando la función del modelo lineal general en nuestro software estadístico, y ver que nos da el mismo estadístico t como la prueba t de arriba, excepto que fue negativa en ese caso por la manera en que nuestro software acomoda los grupos:

```{r echo=FALSE, warning=FALSE}
# print summary of linear regression to perform t-test
lm_summary
```

<!-- We can also view the linear model results graphically (see the right panel of Figure \@ref(fig:PotTVViolin)).  In this case, the predicted value for nonsmokers is $\hat{\beta_0}$ (`r I(sprintf('%0.1f', lm_summary$coefficients[1,1]))`) and the predicted value for smokers is $\hat{\beta_0} +\hat{\beta_1}$ (`r I(sprintf('%0.1f', lm_summary$coefficients[1,1] + lm_summary$coefficients[2,1]))`).  -->
También podemos ver los resultados del model lineal gráficamente (ve el panel derecho de la Figura \@ref(fig:PotTVViolin)). En este caso, el valor predicho para no fumadores es $\hat{\beta_0}$ (`r I(sprintf('%0.1f', lm_summary$coefficients[1,1]))`), y el valor predicho para fumadores es $\hat{\beta_0} +\hat{\beta_1}$ (`r I(sprintf('%0.1f', lm_summary$coefficients[1,1] + lm_summary$coefficients[2,1]))`).

<!-- To compute the standard errors for this analysis, we can use exactly the same equations that we used for linear regression -- since this really is just another example of linear regression.  In fact, if you compare the p-value from the t-test above with the p-value in the linear regression analysis for the marijuana use variable, you will see that the one from the linear regression analysis is exactly twice the one from the t-test, because the linear regression analysis is performing a two-tailed test.   -->
Para calcular los errores estándar para este análisis, podemos usar exactamente las mismas ecuaciones que usamos para regresión lineal -- porque este es realmente sólo otro ejemplo de regresión lineal. De hecho, si comparas el valor p de la prueba t de arriba con el valor p en el análisis de regresión lineal para la variable de uso de marihuana, verás que el del análisis de regresión lineal es exactamente el doble que el de la prueba t, porque el análisis de regresión lineal está realizando una prueba de dos colas.

<!-- ### Effect sizes for comparing two means -->
### Tamaños de efecto para comparar dos medias

<!-- The most commonly used effect size for a comparison between two means is Cohen's d, which (as you may remember from Chapter \@ref(ci-effect-size-power)) is an expression of the effect size in terms of standard deviation units.  For the t-test estimated using the general linear model outlined above (i.e. with a single dummy-coded variable), this is expressed as: -->
El tamaño de efecto más comúnmente usado para comparar dos medias es la d de Cohen, la cual (como recordarás del Capítulo \@ref(ci-effect-size-power)) es una expresión del tamaño del efecto en términos de unidades de desviación estándar. Para la prueba t estimada usando el modelo lineal general desarrollado arriba (i.e. con una sola variable dummy codificada), esto es expresado como:

$$
d = \frac{\hat{\beta_1}}{\sigma_{residual}}
$$
<!-- We can obtain these values from the analysis output above, giving us a d = `r I(sprintf('%0.2f', lm_summary$coefficients[2,1]/lm_summary$sigma))`, which we would generally interpret as a medium sized effect. -->
Podemos obtener estos valores de la salida del análisis arriba, dándonos una d = `r I(sprintf('%0.2f', lm_summary$coefficients[2,1]/lm_summary$sigma))`, que generalmente interpretaríamos como un tamaño de efecto medio.

<!-- We can also compute $R^2$ for this analysis, which tells us how much variance in TV watching is accounted for.  This value (which is reported at the bottom of the summary of the linear model analysis above) is `r I(sprintf('%0.2f',lm_summary$r.squared))`, which tells us that while the effect may be statistically significant, it accounts for relatively little of the variance in TV watching. -->
También podemos calcular $R^2$ para este análisis, que nos dice cuánto de la varianza en tiempo de ver TV es explicada por el modelo. Este valor (que es reportado hasta abajo del resumen del análisis de modelo lineal) es `r I(sprintf('%0.2f',lm_summary$r.squared))`, que nos dice que mientras que el efecto podrá ser estadísticamente significativo, explica relativamente poco de la varianza en tiempo de ver TV.

<!-- ## Bayes factor for mean differences -->
## Factores de Bayes para diferencias entre medias

<!-- As we discussed in the chapter on Bayesian analysis, Bayes factors provide a way to better quantify evidence in favor of or against the null hypothesis of no difference.  We can perform that analysis on the same data: -->
Como discutimos en el capítulo sobre análisis Bayesiano, los factores de Bayes nos proveen de una mejor manera de cuantificar la evidencia a favor o en contra de la hipótesis nula de no diferencia. Podemos calcular este análisis con los mismos datos:

```{r echo=FALSE}
# compute bayes factor for group comparison
# In this case, we want to specifically test against the null hypothesis that the difference is greater than zero - because the difference is computed by the function between the first group ('No') and the second group ('Yes'). Thus, we specify a "null interval" going from zero to infinity, which means that the alternative is less than zero.
bf <- ttestBF(
  formula = TVHrsNum ~ RegularMarij, 
  data = NHANES_sample, 
  nullInterval = c(0, Inf)
)
bf
```

<!-- Because of the way that the data are organized, the second line shows us the relevant Bayes factor for this analysis, which is 61.4. This shows us that the evidence against the null hypothesis is quite strong. -->
Por la manera en que los datos están organizados, la segunda línea nos muestra el factor de Bayes relevante para este análisis, que es 61.4. Esto nos muestra que la evidencia en contra de la hipótesis nula es bastante fuerte.

<!-- ## Comparing paired observations {#paired-ttests} -->
## Comparar observaciones pareadas/relacionadas {#paired-ttests}

<!-- In experimental research, we often use *within-subjects* designs, in which we compare the same person on multiple measurements.  The measurements that come from this kind of design are often referred to as *repeated measures*. For example, in the NHANES dataset blood pressure was measured three times. Let's say that we are interested in testing whether there is a difference in mean systolic blood pressure between the first and second measurement across individuals in our sample (Figure  \@ref(fig:BPfig)). -->
En investigación experimental, frecuentemente usamos diseños *intra-sujetos* (*within-subjects*), en donde comparamos a la misma persona en múltiples mediciones. Las mediciones que se obtienen de este tipo de diseño son frecuentemente referidas como *medidas repetidas* (*repeated measures*). Por ejemplo, en la base de datos NHANES la presión sanguínea fue medida tres veces. Digamos que estamos interesados en probar si existe una diferencia en la presión sanguínea sistólica entre la primera y la segunda medición en las personas de nuestra muestra (Figura \@ref(fig:BPfig)). 


<!-- Left: Violin plot of systolic blood pressure on first and second recording, from NHANES. Right: Same violin plot with lines connecting the two data points for each individual. -->
```{r BPfig, echo=FALSE,fig.cap='Izquierda: Gráfica de violín de la presión sanguínea sistólica en el primer y segundo registro, de NHANES. Derecha: Misma gráfica de violín con líneas conectando los dos registros de una misma persona.',fig.width=8,fig.height=4,out.height='50%'}

set.seed(12345678)

NHANES_sample <- 
  NHANES %>% 
  dplyr::filter(Age>17 & !is.na(BPSys2) & !is.na(BPSys1)) %>%
  dplyr::select(BPSys1,BPSys2,ID) %>%
  sample_n(200)

NHANES_sample_tidy <- 
  NHANES_sample %>%
  gather(timepoint,BPsys,-ID)

NHANES_sample <- 
  NHANES_sample %>%
  mutate(
    diff=BPSys1-BPSys2,
    diffPos=as.integer(diff>0),
    meanBP=(BPSys1+BPSys2)/2
  )

p1 <- ggplot(NHANES_sample_tidy,aes(timepoint,BPsys)) + 
  geom_violin() +
  scale_x_discrete(
    labels = c("Time 1", "Time 2"),
  ) 
p2 <- p1 +geom_line(aes(group=ID))

plot_grid(p1, p2)
```

<!-- We see that there does not seem to be much of a difference in mean blood pressure (about one point) between the first and second measurement. First let's test for a difference using an independent samples t-test, which ignores the fact that pairs of data points come from the the same individuals.    -->
Vemos que no parece haber mucha diferencia en la media de presión sanguínea (cerca de un punto) entre la primera y la segunda medición. Primero probemos si hay una diferencia usando un prueba t para muestras independientes, la cual ignora el hecho que pares de datos vienen de la misma persona.

```{r echo=FALSE}
t.test(
  BPsys ~ timepoint,
  data = NHANES_sample_tidy,
  paired = FALSE, 
  var.equal = TRUE
)
```

<!-- This analysis shows no significant difference. However, this analysis is inappropriate since it assumes that the two samples are independent, when in fact they are not, since the data come from the same individuals.  We can plot the data with a line for each individual to show this (see Figure \@ref(fig:BPfig)). -->
Este análisis muestra que no hay una diferencia estadísicamente significativa. Sin embargo, este análisis es inapropiado porque asume que las dos muestras son independientes, cuando de hecho no lo son, ya que los datos vienen de las mismas personas. Podemos graficar los datos con una línea para cada individuo para mostrar esto (ve la Figura \@ref(fig:BPfig)).

<!-- In this analysis, what we really care about is whether the blood pressure for each person changed in a systematic way between the two measurements, so another way to represent the data is to compute the difference between the two timepoints for each individual, and then analyze these difference scores rather than analyzing the individual measurements. In Figure \@ref(fig:BPDiffHist), we show a histogram of these difference scores, with a blue line denoting the mean difference. -->
En este análisis, lo que realmente nos importa es saber si la presión sanguínea de cada persona cambia de una manera sistemática entre las dos mediciones, así que otra manera de representar estos datos es calculando la diferencia entre dos puntos en el tiempo para cada persona, y luego analizar estas diferencias en lugar de analizar las mediciones individuales. En la Figura \@ref(fig:BPDiffHist) vemos un histograma de estas puntuaciones de diferencias, con una línea azul denotando la media de las diferencias.

<!-- Histogram of difference scores between first and second BP measurement. The vertical line represents the mean difference in the sample. -->
```{r BPDiffHist,echo=FALSE,fig.cap="Histograma de las puntuaciones de diferencias entre la primera y la segunda medición de presión sanguínea. La línea vertical representa la diferencia promedio en la muestra.",fig.width=4,fig.height=4,out.height='50%'}

ggplot(NHANES_sample,aes(diff)) + 
  geom_histogram(bins=30) +
  geom_vline(xintercept = mean(NHANES_sample$diff),color='blue')

```

<!-- ### Sign test -->
### Prueba de los signos

<!-- One simple way to test for differences is using the *sign test*. To do this, we take the differences and compute their sign, and then we use a binomial test to ask whether the proportion of positive signs differs from 0.5. -->
Una manera simple de probar las diferencias es usando la *prueba de los signos*. Para hacer esto, tomamos las diferencias y calculamos su signo, y luego usamos la prueba binomial para preguntarnos si la proporción de signos positivos difiere de 0.5.

```{r echo=FALSE}
# compute sign test for differences between first and second measurement
npos <- sum(NHANES_sample$diffPos)
bt <- binom.test(npos, nrow(NHANES_sample))
bt
```

<!-- Here we see that the proportion of individuals with positive signs (`r I(bt$estimate)`) is not large enough to be surprising under the null hypothesis of $p=0.5$. However, one problem with the sign test is that it is throwing away information about the magnitude of the differences, and thus might be missing something. -->
Aquí vemos que la proporción de personas con signos positivos (`r I(bt$estimate)`) no es suficientemente grande como para ser sorprendente bajo la hipótesis nula de $p=0.5$. Sin embargo, un problema con la prueba de los signos es que está descartando información acerca de la magnitud de las diferencias, y por lo tanto podría estar perdiéndose de algo.

<!-- ### Paired t-test -->
### Prueba t para muestras relacionadas (paired t-test)

<!-- A more common strategy is to use a *paired t-test*, which is equivalent to a one-sample t-test for whether the mean difference between the measurements within each person is zero.  We can compute this using our statistical software, telling it that the data points are paired: -->
Una estrategia más común es usar una *prueba t para muestras relacionadas* (*paired t-test*), que es el equivalente a una prueba t para una muestra en la cual se espera que la media de la diferencias entre mediciones para cada persona sea cero. Podemos calcular esto usando nuestro software estadístico, diciéndole que los datos son pareados/relacionados:

```{r echo=FALSE}
# compute paired t-test
t.test(BPsys ~ timepoint, data = NHANES_sample_tidy, paired = TRUE)

```

<!-- With this analyses we see that there is in fact a significant difference between the two measurements. Let's compute the Bayes factor to see how much evidence is provided by the result: -->
Con este análisis vemos que de hecho existe una diferencia significativa entre las dos mediciones. Calculemos el factor de Bayes para ver cuánta evidencia brinda este resultado:

```{r echo=FALSE}
# compute Bayes factor for paired t-test
ttestBF(x = NHANES_sample$BPSys1, y = NHANES_sample$BPSys2, paired = TRUE)

```

<!-- The observed Bayes factor of 2.97 tells us that although the effect was significant in the paired t-test, it actually provides very weak evidence in favor of the alternative hypothesis. -->
El factor de Bayes observado de 2.97 nos dice que aunque el efecto fue significativo en la prueba t para muestras relacionadas, realmente provee de evidencia muy débil en favor de la hipótesis alternativa.

<!-- The paired t-test can also be defined in terms of a linear model; see the Appendix for more details on this. -->
La prueba t para muestras relacionadas puede también ser definida en términos de un modelo lineal; ve el Apéndice para más detalles sobre esto.

<!-- ## Comparing more than two means -->
## Comparar más de dos medias

<!-- Often we want to compare more than two means to determine whether any of them differ from one another.  Let's say that we are analyzing data from a clinical trial for the treatment of high blood pressure.  In the study, volunteers are randomized to one of three conditions: Drug 1, Drug 2 or placebo.  Let's generate some data and plot them (see Figure \@ref(fig:DrugTrial)) -->
Frecuentemente queremos comparar más de dos medias para determinar si alguna de ellas difiere de las otras. Digamos que estamos analizando datos de un ensayo clínico sobre el tratamiento para presión sanguínea alta. En este estudio, los voluntarios se asignan aleatoriamente a una de tres posibles condiciones: Medicamento 1, Medicamento 2, o placebo. Generemos algunos datos y grafiquémoslos (ve la Figura \@ref(fig:DrugTrial)).

<!-- Box plots showing blood pressure for three different groups in our clinical trial. -->
```{r DrugTrial, echo=FALSE,fig.cap='Boxplots mostrando la presión sanguínea de tres grupos diferentes en nuestro ensayo clínico.',fig.width=4,fig.height=4,out.height='50%'}

set.seed(123456)

nPerGroup <- 36
noiseSD <- 10
meanSysBP <- 140
effectSize <- 0.8
df <- data.frame(
  group=as.factor(c(rep('placebo',nPerGroup),
                    rep('drug1',nPerGroup),
                    rep('drug2',nPerGroup))),
  sysBP=NA) 

df$sysBP[df$group=='placebo'] <- rnorm(nPerGroup,mean=meanSysBP,sd=noiseSD)
df$sysBP[df$group=='drug1'] <- rnorm(nPerGroup,mean=meanSysBP-noiseSD*effectSize,sd=noiseSD)
df$sysBP[df$group=='drug2'] <- rnorm(nPerGroup,mean=meanSysBP,sd=noiseSD)

ggplot(df,aes(group,sysBP)) + geom_boxplot()
```

<!-- ### Analysis of variance {#ANOVA} -->
### Análisis de varianza {#ANOVA}

<!-- We would first like to test the null hypothesis that the means of all of the groups are equal -- that is, neither of the treatments had any effect compared to placebo. We can do this using a method called *analysis of variance* (ANOVA). This is one of the most commonly used methods in psychological statistics, and we will only scratch the surface here.  The basic idea behind ANOVA is one that we already discussed in the chapter on the general linear model, and in fact ANOVA is just a name for a specific version of such a model. -->
Primero querríamos probar la hipótesis nula de que las medias de todos los grupos son iguales -- esto es, ninguno de los tratamientos tuvo ningún efecto comparado con el placebo. Podemos hacer esto usando un método llamado *análisis de varianza* (*analysis of variance*, ANOVA). Este es uno de los métodos más comúnmente usados en estadística en psicología, aquí sólo lo revisaremos superficialmente. La idea básica detrás de ANOVA es una que ya discutimos en el capítulo sobre el modelo lineal general, y de hecho el ANOVA es sólo un nombre para una versión específica de ese modelo.

<!-- Remember from the last chapter that we can partition the total variance in the data ($SS_{total}$) into the variance that is explained by the model ($SS_{model}$) and the variance that is not ($SS_{error}$).  We can then compute a *mean square* for each of these by dividing them by their degrees of freedom; for the error this is $N - p$ (where $p$ is the number of means that we have computed), and for the model this is $p - 1$: -->
Recordarás del capítulo anterior que podemos dividir la varianza total de los datos ($SS_{total}$) en la varianza que es explicada por el modelo ($SS_{model}$) y la varianza que no es explicada por el modelo ($SS_{error}$). Entonces podemos calcular la *media cuadrática* (*mean square*) para cada una de éstas al dividirlas entre sus grados de libertad; para el error, los grados de libertad son $N - p$ (donde $p$ es el número de medias que calculamos), y para el modelo son $p - 1$:

$$
MS_{model} =\frac{SS_{model}}{df_{model}}= \frac{SS_{model}}{p-1}
$$

$$
MS_{error} = \frac{SS_{error}}{df_{error}} = \frac{SS_{error}}{N - p}
$$

<!-- With ANOVA, we want to test whether the variance accounted for by the model is greater than what we would expect by chance, under the null hypothesis of no differences between means.  Whereas for the t distribution the expected value is zero under the null hypothesis, that's not the case here, since sums of squares are always positive numbers.  Fortunately, there is another theoretical distribution that describes how ratios of sums of squares are distributed under the null hypothesis: The *F* distribution (see figure \@ref(fig:FDist)). This distribution has two degrees of freedom, which correspond to the degrees of freedom for the numerator (which in this case is the model), and the denominator (which in this case is the error). -->
Con ANOVA, queremos probar si la varianza explicada por el modelo es mayor que lo que esperaríamos por el azar, bajo la hipótesis nula de no diferencias entre medias. Mientras que para la distribución t el valor esperado es cero bajo la hipótesis nula, ese no es el caso aquí, porque las sumas de cuadrados dan siempre números positivos. Afortunadamente, existe otra distribución teórica que describe cómo las razones de sumas de cuadrados se distribuyen bajo la hipótesis nula: la distribución *F* (ve la Figura \@ref(fig:FDist)). Esta distribución considera dos diferentes grados de libertad, que corresponden a los grados de libertad del numerador (que en este caso es el modelo), y del denominador (que en este caso es el error).

<!-- F distributions under the null hypothesis, for different values of degrees of freedom. -->
```{r FDist, echo=FALSE,fig.cap='Distribuciones F bajo la hipótesis nula, para diferentes valores de los grados de libertad.',fig.width=4,fig.height=4,out.height='50%'}
fdata <- 
  data.frame(x=seq(0.1,10,.1)) %>%
  mutate(
    f_1_1=df(x,1,1),
    f_1_50=df(x,1,50),
    f_10_50=df(x,10,50)
  )

ggplot(fdata,aes(x,f_1_1)) +
  geom_line() +
  geom_line(aes(x,f_1_50),linetype='dotted') +
  geom_line(aes(x,f_10_50),linetype='dashed') +
  labs(y = "Density", x = "F values")

  
```


<!-- To create an ANOVA model, we extend the idea of *dummy coding* that you encountered in the last chapter. Remember that for the t-test comparing two means, we created a single dummy variable that took the value of 1 for one of the conditions and zero for the others.  Here we extend that idea by creating two dummy variables, one that codes for the Drug 1 condition and the other that codes for the Drug 2 condition.  Just as in the t-test, we will have one condition (in this case, placebo) that doesn't have a dummy variable, and thus represents the baseline against which the others are compared; its mean defines the intercept of the model. Using dummy coding for drugs 1 and 2, we can fit a model using the same approach that we used in the previous chapter: -->
Para crear un modelo ANOVA, extendemos la idea de la *codificación ficticia* (*dummy coding*) que presentamos en el capítulo anterior. Recuerda que para la prueba t comparando dos medias, creamos una sola variable ficticia (dummy) que tomó el valor de 1 para una condición y cero para la otra. Aquí extendemos esa idea creando dos variables ficticias (dummy), una que codifica para la condición del Medicamento 1 y la otra que codifica para la condición del Medicamento 2. Justo como en la prueba t, tendremos una condición (en este caso, placebo) que no tiene una variable ficticia (dummy), y por lo tanto representa la línea base contra la cual las otras condiciones son comparadas; su media define el intercepto (origen) del modelo. Usando variables ficticias (dummy) para los medicamentos 1 y 2, podemos ajustar un modelo usando la misma aproximación que usamos en el capítulo anterior:

```{r echo=FALSE}
# create dummy variables for drug1 and drug2
df <-
  df %>%
  mutate(
    d1 = as.integer(group == "drug1"), # 1s for drug1, 0s for all other drugs
    d2 = as.integer(group == "drug2")  # 1s for drug2, 0s for all other drugs
  )

# test model without separate duymmies
lmResultAnovaBasic <- lm(sysBP ~ group, data=df)
emm.result <- emmeans(lmResultAnovaBasic, "group" )
# pairs(emm.result)
```

```{r echo=FALSE}
# fit ANOVA model
lmResultANOVA <- lm(sysBP ~ d1 + d2, data = df)
summary(lmResultANOVA)
```
<!-- The output from this command provides us with two things.  First, it shows us the result of a t-test for each of the dummy variables, which basically tell us whether each of the conditions separately differs from placebo; it appears that Drug 1 does whereas Drug 2 does not.  However, keep in mind that if we wanted to interpret these tests, we would need to correct the p-values to account for the fact that we have done multiple hypothesis tests; we will see an example of how to do this in the next chapter. -->
La salida de este comando nos provee de dos cosas. Primero, nos muestra el resultado de una prueba t para cada una de las variables ficticias (dummy), que básicamente nos dice si cada una de las condiciones separadas difiere del placebo; parece que el Medicamento 1 lo hace, pero el Medicamento 2 no. Sin embargo, ten en cueta que si quisiéramos interpretar estas pruebas, necesitaríamos corregir los valores p para tomar en cuenta el hecho de que hemos realizado múltiples pruebas de hipótesis; veremos un ejemplo de cómo hacer esto en el siguiente capítulo.

<!-- Remember that the hypothesis that we started out wanting to test was whether there was any difference between any of the conditions; we refer to this as an *omnibus* hypothesis test, and it is the test that is provided by the F statistic. The F statistic basically tells us whether our model is better than a simple model that just includes an intercept.  In this case we see that the F test is highly significant, consistent with our impression that there did seem to be differences between the groups (which in fact we know there were, because we created the data). -->
Recuerda que la hipótesis que inicialmente queríamos probar era si había alguna diferencia entre cualquiera de las condiciones; llamamos a esto una prueba de hipótesis *omnibus*, y es la prueba a la que se refiere el estadístico F. El estadístico F básicamente nos dice si nuestro modelo es mejor que un modelo simple que sólo incluye el intercepto. En este caso vemos que la prueba F es altamente significativa, consistente con nuestra impresión de que parece haber diferencias entre los grupos (que de hecho sabemos que sí las hay, porque nosotros creamos los datos).

```{r echo=FALSE}
# Add section on post-hoc tests using emmeans

```

<!-- ## Learning objectives -->
## Objetivos de aprendizaje

<!-- After reading this chapter, you should be able to: -->
Después de leer este capítulo, deberías ser capaz de:

<!-- * Describe the rationale behind the sign test -->
<!-- * Describe how the t-test can be used to compare a single mean to a hypothesized value -->
<!-- * Compare the means for two paired or unpaired groups using a two-sample t-test -->
<!-- * Describe how analysis of variance can be used to test differences between more than two means. -->
* Describir el razonamiento detrás de la prueba de los signos.
* Describir cómo se puede usar la prueba t para comparar una sola media contra un valor hipotetizado.
* Comparar las medias de dos grupos independientes o relacionados usando una prueba t para dos muestras.
* Describir cómo se puede usar el análisis de varianza para probar diferencias entre más de dos medias.


<!-- ## Appendix -->
## Apéndice

<!-- ### The paired t-test as a linear model -->
### La prueba t de muestras relacionadas como un modelo lineal

<!-- We can also define the paired t-test in terms of a general linear model.  To do this, we include all of the measurements for each subject as data points (within a tidy data frame).  We then include in the model a variable that codes for the identity of each individual (in this case, the ID variable that contains a subject ID for each person). This is known as a *mixed model*, since it includes effects of independent variables as well as effects of individuals.  The standard model fitting procedure ```lm()``` can't do this, but we can do it using the ```lmer()``` function from a popular R package called *lme4*, which is specialized for estimating mixed models.  The ```(1|ID)``` in the formula tells `lmer()` to estimate a separate intercept (which is what the ```1``` refers to) for each value of the ```ID``` variable (i.e. for each individual in the dataset), and then estimate a common slope relating timepoint to BP. -->
También podemos definir la prueba t para muestra relacionadas en términos del modelo lineal general. Para hacer esto, incluimos todas las mediciones para cada participante como el conjunto de datos (dentro de un dataframe ordenado). Luego incluimos una variable en el modelo que codifique la identidad de cada persona (en este caso, la variable ID que contiene un ID para cada persona). Esto es conocido como un *modelo mixto*, porque incluye efectos de variables independientes así como efectos de individuos. El procedimiento para ajustar el modelo estándar ```lm()``` no puede hacer esto, pero podemos realizarlo usando la función ```lmer()``` del popular paquete *lme4* en R, que se especializa en estimar modelos mixtos. La parte ```(1|ID)``` en la fórmula le dice a la función `lmer()` que estime un intercepto separado (que es a lo que se refiere el ```1```) para cada valor de la variable ```ID``` (i.e. para cada persona en el conjunto de datos), y luego que estime una pendiente común relacionando el punto en el tiempo con presión sanguínea (BP, blood pressure).

```{r,messages=FALSE}
# compute mixed model for paired test

lmrResult <- lmer(BPsys ~ timepoint + (1 | ID), 
                  data = NHANES_sample_tidy)
summary(lmrResult)
```

<!-- You can see that this shows us a p-value that is very close to the result from the paired t-test computed using the ```t.test()``` function. -->
Puedes ver que esto nos muestra un valor p que es muy cercano al resultado de la prueba t para muestras relacionadas calculado usando la función ```t.test()```.
