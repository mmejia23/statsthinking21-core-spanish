---
output:
  bookdown::gitbook:
    lib_dir: "book_assets"
    includes:
      in_header: google_analytics.html
  pdf_document: default
  html_document: default
---
<!--# Resampling and simulation-->
# Remuestreo y Simulación {#resampling-and-simulation}

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(tidyverse)
library(ggplot2)
library(cowplot)
library(knitr)

set.seed(123456) # set random seed to exactly replicate results

# load the NHANES data library
library(NHANES)

# drop duplicated IDs within the NHANES dataset
NHANES <- NHANES %>% 
  dplyr::distinct(ID,.keep_all=TRUE)

NHANES_adult <- NHANES %>%
  drop_na(Height) %>%
  subset(Age>=18)


```

<!--The use of computer simulations has become an essential aspect of modern statistics. For example, one of the most important books in practical computer science, called *Numerical Recipes*, says the following:-->
El uso de las simulaciones a computadora se ha convertido en un aspecto esencial de la estadística moderna. Por ejemplo, uno de los libros más importantes en informática práctica se llama "Recetas numéricas", y recita lo siguiente: 


<!-- > "Offered the choice between mastery of a five-foot shelf of analytical statistics books and middling ability at performing statistical Monte Carlo simulations, we would surely choose to have the latter skill."-->
> "Si nos ofrecieran la opción entre tener el dominio de una estantería de cinco pies llena de libros de estadística y una mediana capacidad para realizar simulaciones estadísticas a lo Monte Carlo, seguramente elegiríamos la segunda opción."


<!--In this chapter we will introduce the concept of a Monte Carlo simulation and discuss how it can be used to perform statistical analyses.-->
En este capítulo hablaremos del concepto de una simulación Monte Carlo y discutiremos cómo puede ser usada para realizar análisis estadísticos. 

<!--## Monte Carlo simulation-->
## Simulación Monte Carlo

<!--The concept of Monte Carlo simulation was devised by the mathematicians Stan Ulam and Nicholas Metropolis, who were working to develop an atomic weapon for the US as part of the Manhattan Project. They needed to compute the average distance that a neutron would travel in a substance before it collided with an atomic nucleus, but they could not compute this using standard mathematics.
Ulam realized that these computations could be simulated using random numbers, just like a casino game. In a casino game such as a roulette wheel, numbers are generated at random; to estimate the probability of a specific outcome, one could play the game hundreds of times. Ulam's uncle had gambled at the Monte Carlo casino in Monaco, which is apparently where the name came from for this new technique.-->
El concepto de la simulación Monte Carlo fue ideada por los matemáticos Stan Ulam y Nicholas Metropolis, quienes estuvieron trabajando para desarrollar un arma atómica para los Estados Unidos de América, como parte del Proyecto Manhattan. Necesitaban calcular el promedio de la distancia que recorrería un neutrón en una sustancia antes de que chocara con un núcleo atómico, pero no pudieron calcular esto usando matemáticas estándar. 
Ulam notó que estos cálculos podían ser simulados usando números aleatorios, justo como un juego de casino. En un juego de casino, como la ruleta, los números son generados de manera aleatoria; para estimar la probabilidad de un resultado específico, uno podría jugar el juego cientos de veces. El tío de Ulam había jugado en el casino Monte Carlo en Monaco, de ahí viene el nombre para esta nueva técnica. 

<!--There are four steps to performing a Monte Carlo simulation:-->
Hay cuatro pasos a seguir para realizar una simulación Montecarlo:

<!--1. Define a domain of possible values
2. Generate random numbers within that domain from a probability distribution
3. Perform a computation using the random numbers
4. Combine the results across many repetitions-->
1. Definir el dominio posible de los valores
2. Generar números al azar dentro de ese dominio a partir de una distribución de probabilidad
3. Realizar un cálculo usando números aleatorios 
4. Combinar los resultados a través de muchas repeticiones 

<!--As an example, let's say that I want to figure out how much time to allow for an in-class quiz.  We will pretend for the moment that we know that the distribution of quiz completion times is normal, with mean of 5 minutes and standard deviation of 1 minute.  Given this, how long does the test period need to be so that we expect all students to finish the exam 99% of the time? There are two ways to solve this problem.  The first is to calculate the answer using a mathematical theory known as the statistics of extreme values. However, this involves complicated mathematics. Alternatively, we could use Monte Carlo simulation.  To do this, we need to generate random samples from a normal distribution.-->
Como un ejemplo, digamos que quiero descubrir cuánto tiempo debo dejar para un test en clase. Pretenderemos por el momento que sabemos que la distribución del tiempo para completar el test es normal, con una media de 5 minutos y una desviación estándar de 1 minuto. Sabiendo esto, ¿qué tan largo debe ser el periodo de tiempo para que esperemos que todos los estudiantes terminen el examen el 99% del tiempo? Hay dos formas de resolver este problema. El primero es calculando la respuesta usando una teoría matemática conocida como estadística de valores extremos. No obstante, esto requiere matemáticas complejas. De forma alternativa, podríamos usar el método de Montecarlo. Para hacer esto, necesitamos generar muestras aleatorias de una distribución normal. 

<!--## Randomness in statistics-->
## Aleatoriedad en Estadística

<!--The term "random" is often used colloquially to refer to things that are bizarre or unexpected, but in statistics the term has a very specific meaning: A process is *random* if it is unpredictable.  For example, if I flip a fair coin 10 times, the value of the outcome on one flip does not provide me with any information that lets me predict the outcome on the next flip. It's important to note that the fact that something is unpredictable doesn't necessarily mean that it is not deterministic.  For example, when we flip a coin, the outcome of the flip is determined by the laws of physics; if we knew all of the conditions in enough detail, we should be able to predict the outcome of the flip.  However, many factors combine to make the outcome of the coin flip unpredictable in practice.-->
El término "aleatorio" es usado coloquialmente para describir cosas que son bizarras o inesperadas, pero en estadística el término tiene un significado específico: Un proceso se considera *aleatorio* si es impredecible. Por ejemplo, si lanzo una moneda 10 veces, el valor del resultado de una vez que la lances no va a predecir el resultado de la segunda vez que lo lances. Es importante destacar que el hecho de que algo es impredecible, no quiere decir que no es determinista. Por ejemplo, cuando lanzamos una moneda, el resultado de ésta está determinada por las leyes de la física; si supiéramos que todas las condiciones con suficiente detalle, podríamos predecir el resultado de cuando lancemos la moneda. De cualquier forma, son muchos factores los que se combinan para hacer el resultado del lanzamiento de la moneda impredecible en la práctica.  


<!--Psychologists have shown that humans actually have a fairly bad sense of randomness. First, we tend to see patterns when they don't exist. In the extreme, this leads to the phenomenon of *pareidolia*, in which people will perceive familiar objects within random patterns (such as perceiving a cloud as a human face or seeing the Virgin Mary in a piece of toast).  Second, humans tend to think of random processes as self-correcting, which leads us to expect that we are "due for a win" after losing many rounds in a game of chance, a phenomenon known as the "gambler's fallacy".-->
Lxs psicólogxs han demostrado que lxs humanxs tienen un sentido algo ineficiente para la aleatoriedad. En primera instancia, tendemos a ver patrones en donde no existen. De forma extrema, esto nos lleva al fenómeno de la *pareidolia*, en el cual las personas tienden a percibir objetos familiares en patrones aleatorios (como ver una nube con una rostro humano, o ver a la Vírgen María en un pedazo de pan tostado). En segunda instancia, lxs humanxs tienden a pensar en procesos aleatorios como una forma de auto-corrección, lo cual nos lleva a creer que vamos a ganar después de varias rondas de perder un juego de azar, es un fenómeno llamada "la falacia del jugador". 

<!--## Generating random numbers {#generating-random-numbers}-->
## Generando números aleatorios

<!--Running a Monte Carlo simulation requires that we generate random numbers.  Generating truly random numbers (i.e. numbers that are completely unpredictable) is only possible through physical processes, such as the decay of atoms or the rolling of dice, which are difficult to obtain and/or too slow to be useful for computer simulation (though they can be obtained from the [NIST Randomness Beacon](https://www.nist.gov/programs-projects/nist-randomness-beacon])).-->
Hacer correr una simulación con el método de Montecarlo requiere que generemos números aleatorios. Para generar números genuinamente aleatorios (por ejemplo, números que son completamente impredecibles) es solamente posible a través de procesos físicos, como decaimiento de átomos o el rodar unos dados, los cuales son difíciles de obtener o muy lentos como para que sean útiles en una simulación a computadora (aunque pueden obtenerse mediante [NIST Randomness Beacon](https://www.nist.gov/programs-projects/nist-randomness-beacon])).

<!--In general, instead of truly random numbers we use *pseudo-random* numbers generated using a computer algorithm; these numbers will seem random in the sense that they are difficult to predict, but the series of numbers will actually repeat at some point.  For example, the random number generator used in R will repeat after $2^{19937} - 1$ numbers.  That's far more than the number of seconds in the history of the universe, and we generally think that this is fine for most purposes in statistical analysis.-->
En general, en lugar de números verdaderamente aleatorios, podemos usar números *pseudo-aleatorios*, generados utilizando un algoritmo de computadora; estos números pueden aparentar ser aleatorios en el sentido de que son difíciles de predecir, pero las series de números eventualmente se repetirán en algún punto. Por ejemplo, el generador de números aleatorios utilizados en R se repetirán después de $2^{19937} - 1$ números. Eso es mucho más que el número de segundos en la historia de universo, y generalmente pensamos que esto funciona para la mayoría de los propósitos en análisis estadísticos.   

<!--Most statistical software includes functions to generate random numbers for each of the major probability distributions, such as the uniform distribution (all values between 0 and 1 equally), normal distribution, and binomial distribution (e.g. rolling the dice, coin flips).  Figure \@ref(fig:rngExamples) shows examples of numbers generated from uniform and a normal distribution functions.-->
La mayoría de los softwares estadísticos incluyen funciones para generar números aleatorios para cada una de las grandes probabilidades de distribuciones, tal como la distribución uniforme (todos los valores entre 0 y 1 son equitativos), la distribución normal y la distribución binominal (por ejemplo, echar los dados o lanzar una moneda). La Figura \@ref(fig:rngExamples) muestra ejemplos de números generados a partir de funciones de distribución uniformes y normales.

```{r rngExamples,echo=FALSE, fig.cap="Examples of random numbers generated from a uniform (left) or normal (right) distribution.",fig.width=8,fig.height=4,out.height='50%'}

p1 <-
  tibble(
    x = runif(10000)
  ) %>% 
  ggplot((aes(x))) +
  geom_histogram(bins = 100) + 
  labs(title = "Uniform")

p2 <-
  tibble(
    x = rnorm(10000)
  ) %>% 
  ggplot(aes(x)) +
  geom_histogram(bins = 100) +
  labs(title = "Normal")

plot_grid(p1, p2, ncol = 3)
```

<!--One can also generate random numbers for any distribution using a *quantile* function for the distribution. This is the inverse of the cumulative distribution function; instead of identifying the cumulative probabilities for a set of values, the quantile function identifies the values for a set of cumulative probabilities. Using the quantile function, we can generate random numbers from a uniform distribution, and then map those into the distribution of interest via its quantile function.-->
Unx puede también generar números aleatorios por cualquier distribución utilizando una función de *cuantil* para la distribución. Esto es lo inverso de la función de distribución cumulativa; en lugar de identificar las probabilidades cumulativas de un set de valores, la función de cuantiles identifica los valores para un set de probabilidades cumulativas. Usando la función de cuantiles, podemos generar números aleatorios de una distribución uniforme, y después mapearlos en la distribución de interés mediante su función de cuantil.  

<!--By default, the random number generators in statistical software will generate a different set of random numbers every time they are run. However, it is also possible to generate exactly the same set of random numbers, by setting what is called the *random seed* to a specific value.  If you were to look at the code that generated these figures, We will do this in many of the examples in this book, in order to make sure that the examples are reproducible.-->
Por la forma en la que están creados, los generadores de números aleatorios en software estadísticos generan diferentes grupos de números aleatorios cada vez que los eches a correr. Sin embargo, también es posible que generen el mismo grupo de números aleatorios al configurar lo que se llama *semilla aleatoria* (o por su nombre en inglés *random seed*) a un valor específico. Haremos esto en muchos ejemplos en este libro, con el propósito de asegurarnos que los ejemplos sean reproducibles. 

<!--## Using Monte Carlo simulation-->
## Utilizando una simulación con el Método de Montecarlo

<!--Let's go back to our example of exam finishing times. Say that I administer three quizzes and record the finishing times for each student for each exam, which might look like the distributions presented in Figure \@ref(fig:finishingTimes).-->
Regresemos a nuestro ejemplo sobre los tiempos de finalización de un examen. Digamos que administro tres pruebas y grabo los tiempos en que cada alumno termina su examen, lo cual se vería como las distribuciones que se presentan en la Figura \@ref(fig:finishingTimes). 

```{r finishingTimes, echo=FALSE,fig.cap="Simulated finishing time distributions.",fig.width=8,fig.height=4,out.height='50%'}
finishTimeDf <- tibble(finishTime=rnorm(3*150,mean=5,sd=1),
                        quiz=kronecker(c(1:3),rep(1,150)))

ggplot(finishTimeDf,aes(finishTime)) + 
  geom_histogram(bins=25) + 
  facet_grid(. ~ quiz) + 
   xlim(0,10)

```

<!--What we really want to know to answer our question is not what the distribution of finishing times looks like, but rather what the distribution of the *longest* finishing time for each quiz looks like.  To do this, we can simulate the finishing time for a quiz, using the assumption that the finishing times are distributed normally, as stated above; for each of these simulated quizzes, we then record the longest finishing time. We repeat this simulation a large number of times (5000 should be enough) and record the distribution of finishing times, which is shown in Figure \@ref(fig:finishTimeSim).-->
Lo que realmente queremos saber para contestar nuestra pregunta no es cómo se ve la distribución de los tiempos de finalización del examen, sino más bien cómo se ve la distribución del tiempo *más largo* de finalización de cada examen. Para hacer eso, podemos simular el tiempo de finalización para cada examen, asumiendo que los tiempos de finalización están distribuidos de forma normal, como hemos establecido arriba; para cada uno de estas simulaciones de examenes, después grabamos el tiempo más largo de finalización. Repetimos esta simulación un gran número de veces (5000 debería ser suficiente) y luego grabamos la distribución de los tiempos de finalización, lo cual se muestra en la Figura \@ref(fig:finishTimeSim).  

```{r finishTimeSim,echo=FALSE,fig.cap="Distribution of maximum finishing times across simulations.",fig.width=4,fig.height=4,out.height='50%'}

# sample maximum value 5000 times and compute 99th percentile
nRuns <- 5000
sampSize <- 150

sampleMax <- function(sampSize = 150) {
  samp <- rnorm(sampSize, mean = 5, sd = 1)
  return(max(samp))
}

maxTime <- replicate(nRuns, sampleMax())

cutoff <- quantile(maxTime, 0.99)

tibble(maxTime) %>%
  ggplot(aes(maxTime)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = cutoff, color = "red")

```

<!--This shows that the 99th percentile of the finishing time distribution falls at `r I(cutoff)`, meaning that if we were to give that much time for the quiz, then everyone should finish 99% of the time. It's always important to remember that our assumptions matter -- if they are wrong, then the results of the simulation are useless. In this case, we assumed that the finishing time distribution was normally distributed with a particular mean and standard deviation; if these assumptions are incorrect (and they almost certainly are, since it's rare for elapsed times to be normally distributed), then the true answer could be very different.-->
Esto muestra que el percentil número 99 de la distribución de la finalización del examen se encuentra en `r I(cutoff)`, lo cual significa que si diéramos esa cantidad de tiempo para el examen, entonces al menos el 99% de personas deberían de terminar a tiempo. Siempre es importante recordar que nuestras suposiciones importan-- si están mal, entonces los resultados de la simulación serán inservibles. En este caso, asumimos que la distribución del tiempo de finalización estaba distribuido normalmente con una media en particular y una desviación estándar; si estas suposiciones son incorrectas (y casi ciertamente lo son, puesto que es raro que los tiempos de eventos tengan una distribución normal), entonces la respuesta real podría ser muy diferente.   

<!--## Using simulation for statistics: The bootstrap-->
## Usando simulaciones para estadística: The bootstrap

<!--So far we have used simulation to demonstrate statistical principles, but we can also use simulation to answer real statistical questions.  In this section we will introduce a concept known as the *bootstrap* that lets us use simulation to quantify our uncertainty about statistical estimates. Later in the course, we will see other examples of how simulation can often be used to answer statistical questions, especially when theoretical statistical methods are not available or when their assumptions are too difficult to meet.-->
Hasta ahora hemos utilizado simulaciones para demostrar principios estadísticos, pero también podemos usar simulaciones para responder a preguntas estadísticas reales. En esta sección vamos a presentar un concepto conocido como el *bootstrap* (por su nombre en inglés), este nos permite usar simulaciones para cuantificar la incertidumbre de estimaciones estadísticas. Más tarde en este curso, veremos otros ejemplos de cómo la simulación puede ser utilizada en muchas ocasiones para responder preguntas estadísticas, en especial, cuando los métodos de teoría estadística no están disponibles o sus suposiciones son muy difíciles de cumplir. 

<!--### Computing the bootstrap-->
### Calculando el bootstrap

<!--In the previous chapter, we used our knowledge of the sampling distribution of the mean to compute the standard error of the mean.  But what if we can't assume that the estimates are normally distributed, or we don't know their distribution?  The idea of the bootstrap is to use the data themselves to estimate an answer.  The name comes from the idea of pulling one's self up by one's own bootstraps, expressing the idea that we don't have any external source of leverage so we have to rely upon the data themselves.  The bootstrap method was conceived by Bradley Efron of the Stanford Department of Statistics, who is one of the world's most influential statisticians.-->
En el capítulo anterior, utilizamos nuestro conocimiento del muestro de la distribución de la media para calcular el error estándar de la media. Pero ¿qué pasa si no podemos asumir que las estimaciones están distribuidas de forma normal, o si no sabemos su distribución? La idea del bootstrap es usar los mismos datos para estimar la respuesta. El nombre viene de la idea de levantarse a unx mismx por las cuerdas de sus propias botas, expresando la idea de que no necesitamos herramientas externas para utilizar como palanca, así que tenemos que asir de los mismos datos. El método boostrap fue acuñado por Bradley Efron en el Departamento de Estadística de Stanford, quien es uno de los estadísticos más influyentes del mundo.

<!--The idea behind the bootstrap is that we repeatedly sample from the actual dataset; importantly, we sample *with replacement*, such that the same data point will often end up being represented multiple times within one of the samples.  We then compute our statistic of interest on each of the bootstrap samples, and use the distribution of those estimates as our sampling distribution.  In a sense, we treat our particular sample as the entire population, and then repeatedly sample with replacement to generate our samples for analysis. This makes the assumption that our particular sample is an accurate reflection of the population, which is probably reasonable for larger samples but can break down when samples are smaller. -->
La idea detrás del bootstrap es que repetidamente tomamos muestras del conjunto de datos real; lo que es más importante, muestreamos *con reemplazo*, de modo que el mismo punto de datos a menudo terminará representado varias veces en una de las muestras. Después calculamos nuestro interés estadístico en cada una de las muestras del bootstrap, y utilizamos la distribución de esos estimados como nuestra distribución muestral.  En cierto sentido, tratamos a nuestra muestra como si fuera la población completa, y luego muestreamos repetidamente con reemplazo para generar nuestras muestras para el análisis.  Esto se basa en la suposición de que nuestra muestra particular es una representación precisa de la población, lo cual es razonablemente probable para muestras grandes, pero puede quebrantarse cuando las muestras son pequeñas.

<!--Let's start by using the bootstrap to estimate the sampling distribution of the mean of adult height in the NHANES dataset, so that we can compare the result to the standard error of the mean (SEM) that we discussed earlier.-->
Comencemos utilizando el bootstrap para estimar la distribución muestral de la media de alturas de personas adultas en la base de datos NHANES, para que podamos comparar el resultado del error estándar de la media (SEM, *standard error of the mean*), que mencionamos hace unos momentos. 

```{r echo=FALSE}
# perform the bootstrap to compute SEM and compare to parametric method

nRuns <- 2500
sampleSize <- 32

heightSample <- 
  NHANES_adult %>%
  sample_n(sampleSize)

bootMeanHeight <- function(df) {
  bootSample <- sample_n(df, dim(df)[1], replace = TRUE)
  return(mean(bootSample$Height))
}

bootMeans <- replicate(nRuns, bootMeanHeight(heightSample))

SEM_standard <- sd(heightSample$Height) / sqrt(sampleSize)
SEM_bootstrap <- sd(bootMeans)

```

<!-- fig.cap="An example of bootstrapping to compute the standard error of the mean adult height in the NHANES dataset. The histogram shows the distribution of means across bootstrap samples, while the red line shows the normal distribution based on the sample mean and standard deviation." -->
```{r bootstrapSEM,echo=FALSE,fig.cap="Un ejemplo de cálculo de boostrap del error estándar de la media (SEM) de altura de personas adultas en la base de datos NHANES. El histograma muestra la distribución de las medias a lo largo de las diferentes muestras bootstrap, mientras que la línea roja muestra la distribución normal basada en la media y desviación estándar de la muestra.",fig.width=4,fig.height=4,out.height='50%'}

options(pillar.sigfig = 3)

tibble(bootMeans=bootMeans) %>%
  ggplot(aes(bootMeans)) + 
    geom_histogram(aes(y=..density..),bins=50) + 
  stat_function(fun = dnorm, n = 100, 
                args = list(mean = mean(heightSample$Height), 
                            sd = SEM_standard),
                size=1.5,color='red'
                ) 

```

<!--Figure \@ref(fig:bootstrapSEM) shows that the distribution of means across bootstrap samples is fairly close to the theoretical estimate based on the assumption of normality.  We would not usually employ the bootstrap to compute confidence intervals for the mean (since we can generally assume that the normal distribution is appropriate for the sampling distribution of the mean, as long as our sample is large enough), but this example shows how the method gives us roughly the same result as the standard method based on the normal distribution. The bootstrap would more often be used to generate standard errors for estimates of other statistics where we know or suspect that the normal distribution is not appropriate. In addition, in a later chapter you will see how we can also use the bootstrap samples to generate estimates of the uncertainty in our sample statistic as well. -->
La Figura \@ref(fig:bootstrapSEM) muestra que la distribución de la media a través de las muestras del bootstrap es muy cercana al estimado teórico basado en la suposición de normalidad.  Usualmente no usaríamos el bootstrap para calcular intervalos de confianza de la media (puesto que generalmente podemos asumir que la distribución normal es apropiada para la distribución muestral de la media, siempre y cuando nuestra muestra sea lo suficientemente grande), pero este ejemplo muestra cómo este método nos brinda aproximadamente el mismo resultado que el método estándar basado en la distribución normal.  El bootstrap sería más comúnmente usado para generar errores estándar para estimaciones de otros estadísticos donde sabemos o sospechamos que la distribución normal no es apropiada.  Además, en un capítulo posterior revisarás cómo podemos usar también muestras de bootstrap para generar estimaciones de incertidumbre del estadístico de nuestra muestra.   


<!---
```{r echo=FALSE}
# compute bootstrap confidence interval

bootCI <- quantile(bootMeans, c(0.025, 0.975))
#bootCI$type <- c('Bootstrap')

# now let's compute the confidence intervals using the sample mean and SD
sampleMean <- mean(heightSample$Height)
normalCI <- 
  tibble(
  "2.5%" = sampleMean - 1.96 * SEM_standard,
  "97.5%" = sampleMean + 1.96 * SEM_standard
)

allCI <- rbind(normalCI, bootCI)
allCI$type <- c('Normal', 'Bootstrap')
allCI <- allCI %>% dplyr::select(type, `2.5%`, `97.5%`)

kable(allCI, digits=2, 
      caption="Confidence limits for normal distribution and bootstrap methods")
```
--->



<!--## Learning objectives-->
## Objetivos de aprendizaje

<!--After reading this chapter, you should be able to:-->
Después de haber leído este capítulo, deberías ser capaz de:

<!--* Describe the concept of a Monte Carlo simulation.
* Describe the meaning of randomness in statistics
* Describe how pseudo-random numbers are generated
* Describe the concept of the bootstrap-->
* Describir el concepto del método de Montecarlo.
* Describir el significado de la aleatoriedad en estadística.
* Describir cómo son generados los números pseudo-aleatorios.
* Describir el concepto de bootstrap.

<!--## Suggested readings-->
## Lecturas sugeridas

- *Computer Age Statistical Inference: Algorithms, Evidence and Data Science*, by Bradley Efron and Trevor Hastie.
